---
date: 2018-09-10
title: Design
categories:
  - Documentation
type: Document
showSidebar: false
published: false
nav_ordering: 1
pageTitle: "Design"
---

## OPENSABER
OPENSABER is a collection of interfaces, default implementations and configuration tools to enable any knowledge silo to publish data to the external world and allow trusted agents to issue information into it, via secure standards, privacy protected by a consent driven architecture and expressed via a explicit but extensible vocabulary. Thus allowing opensaber implementations as registries to be 5 star Open Data repositories. More on 5 star openness [here](https://www.w3.org/DesignIssues/LinkedData.html){:target="_blank"}.

## Design Considerations
- OPENSABER in it's layered architecture, leverages [RDF](https://www.w3.org/RDF/){:target="_blank"} as the  model to represent data and link interralated data sets.
- OPENSABER would also help define, extend or use existing standard vocabularies to represent various domain constructs. A vocabulary search engine is at [http://lov.okfn.org/dataset/lov/](http://lov.okfn.org/dataset/lov/){:target="_blank"}. It is recommended in LinkedData world to re-use vocabularies if possible.
- An LPG or [labelled property graph](https://github.com/flekschas/owl2neo4j/wiki/What-is-a-labeled-property-graph%3F){:target="_blank"} would be the internal data structure for transaction and computing purposes. Thus requiring a [transformation](https://arxiv.org/abs/1409.3288){:target="_blank"} between the external predicate driven exploded RDF model and a internal denser property Graph representation. In other words, it separates the data model from the data structure and storage.
- OPENSABER modules should be loosely coupled via published interfaces, allowing the open source community to provide implementations and deployers to have control over the choice of middlewares and implementations as necessary. For instance, OPENSABER need not force technology or vendor lock-ins, where possible. More on middleware design can be found [here](/middleware-design.html).
- Trust being a core concern, OPENSABER should design for certifying digitally signed verifiable data.
- Consent driven architecture to satisfy pre or post, single or multiple participants to converge on consensus before data reads or writes. Data protection could be globally defined at the registry or the access patterns could also be modified at a record's attribute or property level.

## Design

### Functional separation

[![layering](/images/opensaber-layering.png)](/images/opensaber-layering.png){:target="_blank"}

OPENSABER expresses data semantically as in any LinkedData repository. Thus, for the consumers of data,data is expressed in vocabulary and an ontology which fits the respective domain and all URIs available for dereferencing via PURLs. So, if an OPENSABER implementation creates a new vocabulary, that implementation will also publish the vocabulary. The SURFACE FORMAT is the serialization format, and respective middleware can be chosen for the choice of format. The format which is gaining ground is [JSON-LD](https://json-ld.org/){:target="_blank"}. However, the Data Model would be RDF, or the facts represented in the triple format (subject-object-predicate). [RDFS](https://www.w3.org/TR/rdf-schema/){:target="_blank"}, [OWL](https://www.w3.org/OWL/){:target="_blank"}, etc could be some of the many schema used for vocabulary definitions.

On the other hand, for scale and performance considerations, the RDF model would be transformed into a labelled property graph model, where Literal objects would collapse into Vertice properties and other Objects to link with labelled Predicate edges.

The Application layer would be free to choose computation in the graph layer or reasoning in the RDF model or any combination available as implemented.

Storage would be abstracted out, so that the graph data structure, could be saved in any DB Provider satisfying the storage interface.

### Processing separation

[![middleware-and-services](/images/middleware-and-services.png)](/images/middleware-and-services.png){:target="_blank"}

A Pipeline design pattern is envisioned to power the various Middlewares which could be plugged in. The Middleware could be chained before application, where we need to address concerns around access, data validations, etc or these could be chained downstream to cater to data privacy, serialization, transport optimizations, etc.

The Application stack could use a multitude of internal microservices/libraries for query, caches, RDF <-> RDF* <-> graph data transformation, crawling and following URIs, executing business functions, batch processing, traversal, storage, etc

### Interfaces

#### Property Graph Data Model

[Blueprints](https://github.com/tinkerpop/blueprints/wiki){:target="_blank"} is a collection of interfaces, implementations, ouplementations, and test suites for the property graph data model. [Providers](http://tinkerpop.apache.org/providers.html){:target="_blank"} lists out graph systems which are TinkerPop-enabled. There is also a [SQLG](https://github.com/pietermartin/sqlg){:target="_blank"} project which is an implementation of TinkerPop3 on a RDBMS. The Blueprints API is now merged under [Gremlin Structure API](http://tinkerpop.apache.org/javadocs/3.3.0/core/org/apache/tinkerpop/gremlin/structure/package-tree.html){:target="_blank"}.

**Gremlin Structure API**

[![gremlin structure API](/images/gremlin.structure.png)](/images/gremlin.structure.png){:target="_blank"}

**Gremlin Traversal API**

[![gremlin traversal API](/images/gremlin.traversal.png)](/images/gremlin.traversal.png){:target="_blank"}


### Data Validation

Since, the data model is in RDF space, the natural choice to perform validations is at the data model layer instead of the structure layer. However, the main challenge is that RDF is built on open world than a closed world definition. So, performing validation on RDF is not a 'natural' ask. As far as validations are concerned, what XML Schema is to XML, RDF Schema is NOT for RDF and is used more for supplementing than validating data.

There have been attempts to perform RDF validations in order to
- Check malformed ingestion
- Debug generation/export of RDF data
- Help domain modellers inform the meaning of "valid" data
- Prompt users to fill correct data
- Execute code on some semantic pattern

```
@prefix : <http://www.w3.org/2012/12/rdf-val/SOTA-ex#> .
@prefix foaf: <http://xmlns.com/foaf/0.1/'> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

<issue7> a :Issue , :SecurityIssue ;
    :state :unassigned ;
    :reportedBy <user6> , <user2> ; # only one reportedBy permitted
    :reportedOn "2012-12-31T23:57:00"^^xsd:dateTime ;
    :reproducedBy <user2>, <user1> ;
    :reproducedOn "2012-11-31T23:57:00"^^xsd:dateTime ; # reproduced before being reported
    :related <issue4>, <issue3>, <issue2> . # referenced issues not included

<issue4> # a ??? - missing type arc
    :state :unsinged ; # misspelled term in value set.
    # :reportedBy ??? - missing required property
    :reportedOn "2012-12-31T23:57:00"^^xsd:dateTime .

<user2> a foaf:Person ;
    foaf:givenName "Alice" ;
    foaf:familyName "Smith" ;
    foaf:phone <tel:+1.555.222.2222> ;
    foaf:mbox <mailto:alice@example.com> .

<user6> a foaf:Agent ; # should be foaf:Person
    foaf:givenName "Bob" ; # foaf:familyName "???" - missing required property
    foaf:phone <tel:+.555.222.2222> ; # malformed tel: URL
    foaf:mbox <mailto:alice@example.com> .
```
 The above errors include:

- missing properties,
- missing or improper type arcs,
- missing referents,
- inconsistent data (issue reproduced before it was reported),
- value not in prescribed value set.

However, in RDF and OWL world, missing semantic information is acceptable, since there could always be more data than currently provided.

Following are possible validation techniques which people have taken with varying results:
- Using SPARQL
    - This technique is very verbose and needs a thorough understanding of SPARQL, hence, not recommended for general purpose use case.
- Defining OWL Constraints
    - Again, extremely tedious and needing one to be an ontologist to create the right constraints
- Resource shapes 
    - [OSLC Resource Shapes](http://open-services.net/bin/view/Main/OSLCCoreSpecAppendixA?sortcol=table;up=#oslc_ResourceShape_Resource){:target="_blank"}
- SPARQL Inferencing Notation (SPIN)
    - This is essentially having a class linked to a specific SPARQL query which validates an instance of a class
    - However, as you can see [here](https://lists.w3.org/Archives/Public/public-rdf-shapes/2014Jul/att-0002/sotaspin-text.spin.ttl){:target="_blank"} the validation rules are fairly complex to write
    - Interesting reads are [here](http://www.w3.org/mid/53B3646D.1010305@topquadrant.com){:target="_blank"} and [example SPIN](http://lists.w3.org/Archives/Public/public-rdf-shapes/2014Jul/att-0002/sotaspin-text.spin.ttl){:target="_blank"}
- Specialised grammar
    - ShEx, inspired from https://en.wikipedia.org/wiki/RELAX_NG seems like a good alternative.
    - [ShEx semantics](http://shex.io/shex-semantics-20170327/){:target="_blank"}
- Others
    -   EyeBall, however it has just fizzled out. I could not find a maintained public artifact well integrating into modern build systems (Maven, etc.)

After going through all the relevant docs, it feels that a declarative layer like ShEx should be a good choice for general purpose validation. However, for validation, a strategy pattern could be used to use other validation strategies, if someone wishes to use SPIN, etc.
    

## Sample Vocabularies

### School and Teacher

[U-DISE based RDF vocabulary](https://github.com/project-sunbird/open-saber/blob/master/sample/vocabulary/teacher.owl){:target="_blank"} translating from [http://dise.in/Downloads/GuidelinesforfillingDCF2014-15.pdf](http://dise.in/Downloads/GuidelinesforfillingDCF2014-15.pdf){:target="_blank"}

#### What is UDISE?

>U-DISE is a database of information about schools in India. The database was developed at the National University for Educational Planning and Administration. It records information such as the level of dropouts and the condition of school toilets. [Wikipedia](https://en.wikipedia.org/wiki/U-DISE){:target="_blank"}

## Sample Validations

Following is a data file and schema file for performing validation. As you can see, it is pretty simple to define constraints for RDF data.

Sample data for 2 schools - 1 rural and 1 urban:

```
@prefix sample: <http://example.com/voc/teacher/1.0.0/> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix sh: <http://www.w3.org/ns/shacl#>

sample:1234 a sample:School ;
    sample:udiseNumber 23456789876 ;
    sample:academicCalendarYearStart "2017"^^xsd:gYear ;
    sample:academicCalendarYearEnd "2018"^^xsd:gYear ;
    sample:schoolName "DAV Public School" ;
    sample:area sample:AreaTypeCode-URBAN ;
    sample:address _:urbanaddress ;
    sample:clusterResourceCentre "some Cluster Resource" ;
    sample:revenueBlock "some block" ;
    sample:assemblyConstituency "Gurgaon" .

_:urbanaddress a sample:IndianUrbanPostalAddress ;
    sample:mohalla "Sector 14" ;
    sample:wardNumber "456" ;
    sample:municipality "MCG" ;
    sample:city "Gurgaon" ;
    sample:pinCode 122001 ;
    sample:district "Gurgaon" .

sample:1235 a sample:School ;
    sample:udiseNumber 11111111111 ;
    sample:academicCalendarYearStart "2017"^^xsd:gYear ;
    sample:academicCalendarYearEnd "2018"^^xsd:gYear ;
    sample:schoolName "ARARIA Gov School" ;
    sample:area sample:AreaTypeCode-RURAL ;
    sample:address _:ruraladdress ;
    sample:clusterResourceCentre "some Cluster Resource" ;
    sample:revenueBlock "some block" ;
    sample:assemblyConstituency "ARARIA" .

_:ruraladdress a sample:IndianRuralPostalAddress ;
    sample:habitation "ARARIA" ;
    sample:villageName "ARARIA" ;
    sample:villagePanchayat "ARARIA BASTI" ;
    sample:pinCode 854311 ;
    sample:district "ARARIA" .

sample:SchoolShape sh:targetNode sample:1234 .
sample:AddressShape sh:targetNode _:urbanaddress .
sample:AddressShape sh:targetNode _:ruraladdress .
```

Schema file for validating data:

```
PREFIX sample: <http://example.com/voc/teacher/1.0.0/>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
PREFIX ex: <http://ex.example/#>

sample:isAYear xsd:gYear
sample:isAString xsd:string

sample:SchoolShape {
    sample:udiseNumber xsd:integer TotalDigits 11 ;
    sample:academicCalendarYearStart @sample:isAYear ;
    sample:academicCalendarYearEnd @sample:isAYear ;
    sample:area [sample:AreaTypeCode-RURAL sample:AreaTypeCode-URBAN] ;
    sample:schoolName @sample:isAString 
}

sample:AddressShape {
    a [sample:IndianUrbanPostalAddress sample:IndianRuralPostalAddress] ;
    (
        sample:mohalla @sample:isAString ;
        sample:wardNumber @sample:isAString ;
        sample:municipality @sample:isAString ;
        sample:city @sample:isAString 
        |
        sample:habitation @sample:isAString ;
        sample:villageName @sample:isAString ;
        sample:villagePanchayat @sample:isAString ;
    );
    sample:pinCode xsd:integer TotalDigits 6 ;
    sample:district @sample:isAString
}
```

You can check the same on an online validator at [online validator](http://shaclex.herokuapp.com/validate?schemaEmbedded=false&triggerMode=shapeMap){:target="_blank"}

## Good reads

### RDF

[RDF Primer](https://www.w3.org/TR/rdf11-primer/){:target="_blank"}
[Attempts to validate RDF](https://www.w3.org/2012/12/rdf-val/SOTA){:target="_blank"}

### Saving RDF

[Triple stores vs Labelled Property Graph](https://neo4j.com/blog/rdf-triple-store-vs-labeled-property-graph-difference/){:target="_blank"}

[Reconciliation of RDF* and Property Graphs](https://arxiv.org/abs/1409.3288){:target="_blank"}


### Shape Expressions (ShEx) for RDF data validations

> ShEx is designed to fill a long-recognized gap in Semantic Web technology. The Resource Description Framework language (RDF), and the more expressive Web Ontology Language (OWL), were designed for making statements about things "in the world" or, more precisely, about things in a conceptual caricature of the world. Things in that caricature may include anything from people, books, abstract ideas, and Web pages to planets or refrigerators. By design, RDF and OWL were optimized for aggregating information from multiple sources and for processing incomplete information. If a model in OWL says that a person has two biological parents, and only one parent is described in a given graph, an OWL processor will not report a mismatch between the model and the graph because the second parent is assumed to exist even if it is not described in the data. In other words, the graph could describe the second parent if more triples were supplied. In logic, this is called the "open world assumption".

quoting [ShEx Primer](http://shexspec.github.io/primer){:target="_blank"}

[IBM's position on RDF Validation in 2014](https://lists.w3.org/Archives/Public/public-rdf-shapes/2014Jul/0246.html){:target="_blank"}

[StarDog doing RDF validation](https://gist.github.com/evren/5612900#file-sota-example-out){:target="_blank"} - But StarDog is a commercial product, alas!

### Tools

[Semantic Web Tools](https://www.w3.org/2001/sw/wiki/SemanticWebTools){:target="_blank"}
